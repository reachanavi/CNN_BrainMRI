{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d63cbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install opencv-python\n",
    "# !pip install pillow\n",
    "\n",
    "\n",
    "# Data: https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri/data\n",
    "#Example Code: https://www.kaggle.com/code/vivekreddyloka/brain-tumor-classification-using-cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5f3d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these two blocks to load important libraries and set things up\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40ec6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fba999f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        label_encoder = LabelEncoder()\n",
    "        self.images = images\n",
    "        self.labels = label_encoder.fit_transform(labels)\n",
    "#         self.images = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0942ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/Training'\n",
    "test_path = 'data/Testing'\n",
    "labels = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
    "x_train = []\n",
    "Y_train = []\n",
    "x_test = []\n",
    "Y_test = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(train_path,label)\n",
    "    for file_name in os.listdir(path):\n",
    "#         print(file_name)\n",
    "        image = cv2.imread(os.path.join(path,file_name))\n",
    "#         print(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (180, 180))\n",
    "        pil_image = Image.fromarray(image)\n",
    "        tensor_image = transform(pil_image)\n",
    "        x_train.append(tensor_image)\n",
    "        Y_train.append(label)\n",
    "        \n",
    "    path = os.path.join(test_path,label)\n",
    "    for file_name in os.listdir(path):\n",
    "        image = cv2.imread(os.path.join(path,file_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (180, 180))\n",
    "        pil_image = Image.fromarray(image)\n",
    "        tensor_image = transform(pil_image)\n",
    "        x_test.append(tensor_image)\n",
    "        Y_test.append(label)\n",
    "\n",
    "train_set = ImgDataset(x_train, Y_train)\n",
    "test_set = ImgDataset(x_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b5a4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f75fca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.LazyLinear(4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "        y = self.pool1(self.conv1(x))\n",
    "        y = self.pool2(self.conv2(y))\n",
    "        y = self.linear(self.flatten(self.relu(y)))\n",
    "#         print(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "714ca3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0205\n",
      "Epoch [2/10], Loss: 0.4876\n",
      "Epoch [3/10], Loss: 0.2621\n",
      "Epoch [4/10], Loss: 0.1301\n",
      "Epoch [5/10], Loss: 0.0830\n",
      "Epoch [6/10], Loss: 0.0442\n",
      "Epoch [7/10], Loss: 0.0237\n",
      "Epoch [8/10], Loss: 0.0125\n",
      "Epoch [9/10], Loss: 0.0053\n",
      "Epoch [10/10], Loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ae22cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 73.35%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(correct/total)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1219dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.LazyLinear(4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "        y = self.pool1(self.conv1(x))\n",
    "        y = self.pool2(self.conv2(y))\n",
    "        y = self.linear(self.dropout(self.flatten(self.relu(y))))\n",
    "        \n",
    "#         print(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3097131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9545\n",
      "Epoch [2/10], Loss: 0.5151\n",
      "Epoch [3/10], Loss: 0.3856\n",
      "Epoch [4/10], Loss: 0.3210\n",
      "Epoch [5/10], Loss: 0.2414\n",
      "Epoch [6/10], Loss: 0.2074\n",
      "Epoch [7/10], Loss: 0.1831\n",
      "Epoch [8/10], Loss: 0.1498\n",
      "Epoch [9/10], Loss: 0.1405\n",
      "Epoch [10/10], Loss: 0.1114\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3998bc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 71.32%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(correct/total)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "235a3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.LazyLinear(4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "        y = self.pool1(self.bn1(self.conv1(x)))\n",
    "        y = self.pool2(self.bn2(self.conv2(y)))\n",
    "        y = self.linear(self.flatten(self.relu(y)))\n",
    "        \n",
    "#         print(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70a7eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 8.1451\n",
      "Epoch [2/10], Loss: 2.0307\n",
      "Epoch [3/10], Loss: 1.8081\n",
      "Epoch [4/10], Loss: 1.0787\n",
      "Epoch [5/10], Loss: 0.9704\n",
      "Epoch [6/10], Loss: 0.4971\n",
      "Epoch [7/10], Loss: 0.3548\n",
      "Epoch [8/10], Loss: 0.3436\n",
      "Epoch [9/10], Loss: 0.1484\n",
      "Epoch [10/10], Loss: 0.3213\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel3()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    losses.append(running_loss/len(train_loader))\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afdae9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot the loss numbers\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee163cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 76.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(correct/total)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e79a5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'experiment'\n",
    "labels = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
    "x_train = []\n",
    "Y_train = []\n",
    "x_test = []\n",
    "Y_test = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(test_path,label)\n",
    "    for file_name in os.listdir(path):\n",
    "        image = cv2.imread(os.path.join(path,file_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (180, 180))\n",
    "        pil_image = Image.fromarray(image)\n",
    "        tensor_image = transform(pil_image)\n",
    "        x_test.append(tensor_image)\n",
    "        Y_test.append(label)\n",
    "\n",
    "test_set_child = ImgDataset(x_test, Y_test)\n",
    "test_loader_child = DataLoader(test_set_child, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22c949ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 42.86%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_child:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(correct/total)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28c57aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.LazyLinear(4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(x)\n",
    "        y = self.pool1(self.bn1(self.conv1(x)))\n",
    "        y = self.pool2(self.bn2(self.conv2(y)))\n",
    "        y = self.linear(self.dropout(self.flatten(self.relu(y))))\n",
    "        \n",
    "#         print(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "144393af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6.2592\n",
      "Epoch [2/10], Loss: 3.2436\n",
      "Epoch [3/10], Loss: 1.8299\n",
      "Epoch [4/10], Loss: 1.2958\n",
      "Epoch [5/10], Loss: 1.3388\n",
      "Epoch [6/10], Loss: 2.0282\n",
      "Epoch [7/10], Loss: 1.0051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         print(labels)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[96], line 19\u001b[0m, in \u001b[0;36mCNNModel4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#         print(x)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m---> 19\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(y))))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         print(y)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel4()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: {(correct/total)*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
